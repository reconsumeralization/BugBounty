# OpenAI O1 Configuration
OPENAI_API_KEY="your-api-key-here"
O1_MODEL="o1-mini"  # Use "o1" for more complex analysis
O1_MAX_COMPLETION_TOKENS=25000  # Reserve space for reasoning
O1_API_ENDPOINT="https://api.openai.com/v1"

# O1 Model Settings
O1_CONTEXT_WINDOW=128000  # 128k for o1-mini, 200k for o1
O1_REASONING_BUFFER=25000  # Minimum tokens for reasoning
O1_TEMPERATURE=0.1  # Lower temperature for focused analysis

# Analysis Configuration
ANALYSIS_BATCH_SIZE=5  # Number of files to analyze in parallel
ANALYSIS_TIMEOUT=300  # Increased timeout for complex analysis
ANALYSIS_RETRIES=3  # Number of retries for failed analysis
ANALYSIS_MIN_CONFIDENCE=0.8  # Minimum confidence threshold

# Rate Limiting
RATE_LIMIT_REQUESTS=50  # Reduced for longer processing times
RATE_LIMIT_PERIOD=3600
RATE_LIMIT_BURST=5

# Caching
CACHE_TTL_HOURS=24
CACHE_MAX_ENTRIES=1000
CACHE_MIN_TOKENS=1000  # Minimum tokens to cache

# Logging
LOG_LEVEL=INFO
LOG_FILE=o1_analysis.log
LOG_FORMAT="%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Security Settings
ALLOWED_DOMAINS=*.infomaniak.com,*.infomaniak.ch
MAX_PAYLOAD_SIZE=1048576
MIN_CODE_SIZE=10  # Minimum lines of code to analyze
MAX_CODE_SIZE=10000  # Maximum lines of code to analyze

# Metrics
ENABLE_METRICS=true
METRICS_PORT=9090
METRICS_PATH=/metrics
COLLECT_REASONING_METRICS=true  # Track reasoning token usage
